# 线性模型
> 本章讲的都是监督学习线性模型

1. 线性回归       (p53)
    - wx + b = y
    - 连续
    - 均方误差最小
 
2. 令g(y)=wx+b可以构造**广义线性模型**，其中g为联系函数 (p57)

3. 线性分类       (p57)
    - 找单调可微函数将线性回归连续结果映射到离散标记值
    - sigmoid函数另一个形式ln(y/(1-y)) = wx+b
    
4. 线性判别分析(LDA)    (p60)
    - 有监督的线性分类器 y=wx
    - 将高维样本映射到低维空间，并使得类内方差最小，类间距离最大
    - 需要用到广义瑞利商与矩阵分解

5. 多分类学习(N类)   (p63)
    - 一对一(OvO):  需要训练N(N-1)/2个二分类器
    - 一对其余(OvR):    需要训练N个二分类器
    - 多对多(MvM):  OvO与OvR都是MvM的特例
        - 一种常见方法是“纠错输出码(ECOC)”

6. 类别不平衡问题    (p66)
    - 如果1000个样本999个反例，正例只有1个，则分类器只要全部预测为负，精度就可达到99%
    - 基本策略：
        - 对训练集中的反例进行欠采样，去除一部分反例使得正反例数目接近
        - 对训练集中的正例进行过采样，即增加一些正例使得正反例数目接近
        - 直接基于原始训练集进行学习，但在用训练好的分类器进行预测时进行阈值移动

