# 统计学习方法　李航
## 第一章 统计学习方法概论
- **统计学习**是关于计算机基于数据构建概率统计模型并运用模型对数据进行分析和预测的一门学科。
    - 统计学习包括监督学习、非监督学习(最典型是聚类)、半监督学习和强化学习。本书主要讨论监督学习。

- 统计学习三要素  p6
    - **模型**：构造假设空间，确定所要学习的模型形式；
    - **策略**：获取目标函数，也就是损失函数或者风险函数；
    - **算法**：依据模型与策略获取最优解的方法，也叫优化函数，比如梯度下降等；
        - 全局梯度下降
        - 批量梯度下降
        - 随机梯度下降
        - Adam

- 损失函数与风险函数  p7
    - **损失函数**：用来度量预测错误的程度，通常是一个非负实值函数
    - **风险函数**：经验风险与结构风险

- 经验风险与结构风险  p8
    - **经验风险**：模型关于训练数据集的平均损失。经验风险最小化的一个例子是极大似然估计，只考虑经验风险的学习效果未必好，有可能出现**过拟合**现象。
    - **结构风险**：为了防止过拟合而提出在经验风险上加上表示**模型复杂度**的正则化项。正则化项有多种不同形式（比如L1与L2），结构风险最小化也叫作正则化。

- **过拟合**：指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。 p11
    - 模型复杂度对训练误差和测试误差的影响  p13

- **模型选择**的常见依据
    - 正则化
    - 交叉验证

- **正则化项**：表示模型复杂度的修正项，可以是参数向量的L1、L2范数等。  p14
    - 奥卡姆剃刀原理：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型。
    - 从**贝叶斯估计的角度**看，正则化项对应于模型的先验概率（复杂模型具有较小的先验概率，简单的模型具有较大的先验概率）。

- **交叉验证**：将数据集进行划分为训练集、验证集、测试集等，在其中训练集上进行训练，并用验证集进行模型选择  p14
    - 简单交叉验证
   　- S折交叉验证
    - 留一交叉验证

- **泛化能力**：学习方法对于**未知**数据的预测能力。 p15
    - 泛化误差与泛化误差上界（书上此处**没看懂**）

- **监督学习方法**可以分为生成方法与判别方法  p18
    - **生成**方法：由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即**生成模型**。（典型如朴素贝叶斯法、隐马尔科夫等）
    - **判别**方法：由数据直接学习决策函数f(X)或条件概率分布P(Y|X)作为预测的模型，即**判别模型**。（典型如k近邻法、感知机、决策树、支持向量机等）
　
- **分类问题**：当输出变量Y取有限个离散值时，预测问题便成为分类问题。  p18
    - 常见二分类问题评价指标有：**准确率**(accuracy)、**精确率**(precision)与**召回率**(recall)  p19

- **标注问题**：输入为一个观测序列，输出是一个对应的标记序列  p20
    - 通常通过条件概率分布模型来进行标记序列的生成
    - 标注问题在信息抽取、自然语言处理等领域被广泛应用，一个例子：输入一个由单词组成的句子，对句子中每一个单词进行词性标注。
    - 常用的统计学习方法：隐马尔可夫模型、条件随机场
       
- **回归问题**：用来预测输入变量(自变量)和输出变量(因变量)之间的连续映射关系。回归问题的学习等价于函数拟合。例如使用RANSAC进行关键点匹配对筛选时学习出单应矩阵就是一种回归问题的体现。
    - 回归问题按照输入变量的个数，分为一元回归与多元回归；按照输入输出变量之间关系的类型可分为线性回归与非线性回归；
    - 回归问题最常用的损失函数是平方损失函数，此情况下，回归问题可以由最小二乘法求解；
